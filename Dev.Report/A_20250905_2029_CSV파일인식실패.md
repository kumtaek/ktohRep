# A_20250905_2029_CSV파일인식실패.md

## 문제점 정확한 진단 결과

코드 분석과 실제 테스트를 통해 CSV 파일이 인식되지 않는 **정확한 원인**을 발견했습니다.

## 핵심 원인 분석

### **🔍 실제 테스트 결과**

**파일 스캔 테스트 결과**:
```
Found CSV: E:\SourceAnalyzer.git\project\sampleSrc\db_schema\ALL_TABLES.csv
Found CSV: E:\SourceAnalyzer.git\project\sampleSrc\db_schema\ALL_TAB_COLUMNS.csv  
Found CSV: E:\SourceAnalyzer.git\project\sampleSrc\db_schema\ALL_VIEWS.csv
Found CSV: E:\SourceAnalyzer.git\project\sampleSrc\db_schema\PK_INFO.csv
Total CSV files found: 4
```

**결론**: ✅ **파일 스캔은 정상적으로 작동함** (4개 파일 모두 발견)

### **🔴 진짜 문제: CSV 파서 미등록**

**파일**: `phase1/main.py:471-501`

```python
def _select_parser_for_file(self, file_path: str, file_type: str):
    """파일 타입에 따라 적절한 파서를 선택합니다."""
    file_ext = Path(file_path).suffix.lower()
    
    if file_ext == '.java':
        return self.parsers.get('java')
    elif file_ext == '.jsp':
        return self.parsers.get('jsp_mybatis')
    elif file_ext == '.xml':
        # XML 처리 로직
    elif file_ext == '.sql':
        return self.parsers.get('sql')
    elif file_ext == '.properties':
        return self.parsers.get('spring')
    # ❌ CSV 파일에 대한 처리가 없음
    
    return None  # ← CSV 파일은 여기서 None 반환
```

### **🔴 처리 흐름 문제**

1. **파일 스캔**: ✅ CSV 파일 4개 정상 발견
2. **파일 그룹핑**: ✅ `csv` 그룹에 정상 추가
3. **파서 선택**: ❌ `_select_parser_for_file()`에서 `None` 반환
4. **에러 처리**: ❌ "적절한 파서를 찾을 수 없음" 경고 후 스킵
5. **결과**: DB에 파일 정보 저장되지 않음

### **🔍 로그 확인 예상**

```
WARNING: 적절한 파서를 찾을 수 없음: project/sampleSrc/db_schema/ALL_TABLES.csv
WARNING: 적절한 파서를 찾을 수 없음: project/sampleSrc/db_schema/ALL_TAB_COLUMNS.csv
WARNING: 적절한 파서를 찾을 수 없음: project/sampleSrc/db_schema/ALL_VIEWS.csv
WARNING: 적절한 파서를 찾을 수 없음: project/sampleSrc/db_schema/PK_INFO.csv
```

## 단계별 해결 방안

### **🔧 1단계: CSV 파서 선택 로직 추가 (즉시 해결 가능)**

**수정 위치**: `phase1/main.py:471-501`

```python
def _select_parser_for_file(self, file_path: str, file_type: str):
    """파일 타입에 따라 적절한 파서를 선택합니다."""
    file_ext = Path(file_path).suffix.lower()
    
    if file_ext == '.java':
        return self.parsers.get('java')
    elif file_ext == '.jsp':
        return self.parsers.get('jsp_mybatis')
    elif file_ext == '.xml':
        # 기존 XML 처리 로직
    elif file_ext == '.sql':
        return self.parsers.get('sql')
    elif file_ext == '.properties':
        return self.parsers.get('spring')
    elif file_ext == '.csv':  # ✅ 추가
        # CSV 파일은 단순 파일 메타정보만 저장 (내용 파싱 없음)
        return 'csv_metadata_only'  # 특수 식별자
    
    return None
```

### **🔧 2단계: CSV 파일 처리 로직 추가**

**수정 위치**: `phase1/main.py:414-469`

```python
async def _analyze_single_file(self, file_path: str, project_id: int, file_type: str):
    """단일 파일을 분석합니다."""
    try:
        # 파일 타입에 따라 적절한 파서 선택
        parser = self._select_parser_for_file(file_path, file_type)
        if not parser:
            self.logger.warning(f"적절한 파서를 찾을 수 없음: {file_path}")
            await self._save_parsing_error(file_path, project_id, "파서를 찾을 수 없음", "ParserNotFound")
            return
        
        # CSV 파일 특수 처리 추가
        if parser == 'csv_metadata_only':  # ✅ 추가
            # CSV 파일은 메타정보만 저장 (내용 파싱 없음)
            file_id = await self._save_file_info(file_path, project_id)
            await self._save_csv_metadata(file_id, file_path, project_id)
            return
            
        # 기존 처리 로직...
```

### **🔧 3단계: CSV 메타데이터 저장 메서드 추가**

```python
async def _save_csv_metadata(self, file_id: int, file_path: str, project_id: int):
    """CSV 파일 메타데이터 저장"""
    try:
        with self.db_manager.get_auto_commit_session() as session:
            import os
            
            # 파일 기본 정보
            file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
            
            # CSV 파일 정보 요약
            csv_info = {
                'file_type': 'csv',
                'purpose': 'db_schema' if 'db_schema' in file_path else 'data',
                'size_bytes': file_size,
                'estimated_rows': self._estimate_csv_rows(file_path),
                'encoding': 'utf-8'
            }
            
            # 파싱 결과 저장
            parse_result = ParseResultModel(
                file_id=file_id,
                parser_type='csv',
                success=True,
                parse_time=0.1,
                ast_complete=True,  # CSV는 구조가 단순하므로 완전 파싱으로 간주
                partial_ast=False,
                fallback_used=False,
                error_message=None,
                confidence=1.0,
                metadata=json.dumps(csv_info)
            )
            session.add(parse_result)
            session.flush()
            
            self.logger.info(f"CSV 메타데이터 저장 완료: {file_path}")
            
    except Exception as e:
        self.logger.error(f"CSV 메타데이터 저장 실패 {file_path}: {e}")

def _estimate_csv_rows(self, file_path: str) -> int:
    """CSV 행 수 추정 (성능을 위해 간단한 라인 카운트)"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return sum(1 for _ in f) - 1  # 헤더 제외
    except:
        return 0
```

## 우선순위별 구현 계획

### **🚀 Phase 1: 긴급 해결 (10분 작업)**
1. ✅ `_select_parser_for_file()`에 CSV 처리 추가
2. ✅ `_analyze_single_file()`에 CSV 특수 처리 로직 추가
3. ✅ 기본 CSV 메타데이터 저장 구현

**결과**: CSV 파일 4개가 files 테이블에 저장됨

### **🔧 Phase 2: 기능 향상 (30분 작업)**
1. CSV 내용 검증 (헤더 구조, 데이터 품질)
2. DB 스키마 CSV와 일반 CSV 구분 처리
3. CSV 파일 변경 감지 및 증분 업데이트

### **📊 Phase 3: 통합 관리 (1시간 작업)**
1. DB 스키마 CSV와 소스파일 스캔 결과 연계
2. CSV 파일 의존성 추적 (어떤 코드가 어떤 CSV를 참조하는지)
3. 스키마 변경 영향도 분석 기능

## 예상 효과

### **Phase 1 완료 후**
- **CSV_파일**: 0개 → 4개 (100% 해결)
- **파일 인식률**: 20/24개 → 24/24개 (100% 완성)
- **메타정보 완전성**: 프로젝트 내 모든 파일 추적 가능

### **부가 효과**
- **일관성**: 모든 파일 타입에 대한 균일한 메타데이터 관리
- **확장성**: 향후 다른 데이터 파일(JSON, YML 등) 처리 기반 마련
- **추적성**: DB 스키마 파일 변경 이력 관리 가능

## 권장 조치

### **즉시 실행 (Critical)**
```bash
# 1. CSV 파서 로직 추가
# 2. 메타데이터 저장 메서드 구현
# 3. 테스트 실행으로 검증
```

### **후속 작업 (Enhancement)**
1. 🔍 CSV 내용 품질 검증 기능
2. 📈 DB 스키마 변경 감지 시스템
3. 🔗 소스코드-스키마 의존성 매핑

---

**분석 완료일시**: 2025-09-05 20:29:00  
**분석자**: SourceAnalyzer Technical Team  
**진단 상태**: ✅ 원인 정확히 파악됨  
**해결 난이도**: Easy (파서 로직 추가만 필요)  
**예상 작업 시간**: 10분 (Phase 1 기준)