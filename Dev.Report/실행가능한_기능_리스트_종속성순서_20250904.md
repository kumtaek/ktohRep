# 실행가능한 기능 리스트 (종속성 순서)

## 📅 작성일시
- **작성일**: 2025년 09월 04일 13시 25분
- **작성자**: Cursor AI Assistant
- **특징**: 종속성을 고려한 실행 순서

---

## 🔗 종속성 분석

### 종속성 구조
```
1. 기본 인프라 (의존성 없음)
   ├── AI 모델 클라이언트
   ├── 메타데이터베이스 구축
   └── 기본 분석 도구들

2. 분석 도구들 (기본 인프라 의존)
   ├── 계층도 분석
   ├── ERD 분석
   └── AI 분석

3. 통합 도구들 (분석 도구들 의존)
   ├── AI 컴포넌트 다이어그램
   └── 종합 리포트 생성
```

---

## 🚀 실행 순서별 기능 목록

### 1단계: 기본 인프라 및 설정 확인

#### 1-1. AI 모델 클라이언트 테스트
**목적**: AI 모델 연결 상태 확인
**의존성**: 없음 (최우선 실행)

```bash
python ai_model_client.py
```

**확인사항**:
- Ollama 서비스 실행 상태
- gemma3:1b 모델 설치 상태
- vLLM 연결 상태 (운영환경)

---

#### 1-2. 메타데이터베이스 구축 (필요시)
**목적**: 소스 분석을 위한 메타데이터베이스 생성
**의존성**: 없음

```bash
python main.py --project-name sampleSrc --clean
```

**확인사항**:
- `../project/sampleSrc/metadata.db` 파일 생성
- 파서가 정상적으로 소스 분석 완료

---

### 2단계: 기본 분석 도구들

#### 2-1. Java 프로젝트 계층도 분석
**목적**: 프로젝트 구조 파악
**의존성**: 프로젝트 소스 파일만 있으면 실행 가능
**우선순위**: 높음 (다른 분석의 기초)

```bash
python generate_hierarchy_report.py --project-name sampleSrc
```

**출력**: `계층도분석리포트_YYYYMMDD_HHMMSS.md`
**소요시간**: 0.02초

---

#### 2-2. 데이터베이스 ERD 분석
**목적**: 데이터베이스 구조 파악
**의존성**: DB_SCHEMA 폴더의 CSV 파일
**우선순위**: 높음 (데이터 구조 이해)

```bash
python generate_erd_report.py --project-name sampleSrc
```

**출력**: `erd_YYYYMMDD_HHMMSS.md`
**소요시간**: 0.01초

---

#### 2-3. AI 기반 소스코드 분석
**목적**: AI를 활용한 종합적인 소스 분석
**의존성**: AI 모델 클라이언트 (1-1단계 완료 필요)
**우선순위**: 중간

```bash
# 기본 종합 분석
python generate_ai_report.py --project-name sampleSrc

# 특정 분석 유형
python generate_ai_report.py --project-name sampleSrc erd local_gemma
python generate_ai_report.py --project-name sampleSrc security local_gemma
python generate_ai_report.py --project-name sampleSrc code_quality local_gemma
```

**출력**: `ai_analysis_YYYYMMDD_HHMMSS.md`
**소요시간**: 60-120초

---

### 3단계: 통합 분석 도구들

#### 3-1. AI 컴포넌트 다이어그램 생성
**목적**: 계층도 + AI 분석을 통합한 상세 다이어그램
**의존성**: 
- AI 모델 클라이언트 (1-1단계)
- 프로젝트 소스 구조 (2-1단계 권장)
**우선순위**: 높음 (최종 결과물)

```bash
python generate_ai_component_diagram.py --project-name sampleSrc
```

**출력**: `ai_컴포넌트다이어그램_YYYYMMDD_HHMMSS.md`
**소요시간**: 50-60초

---

#### 3-2. AI 컴포넌트 분석기 개별 테스트
**목적**: AI 컴포넌트 분석기의 개별 기능 테스트
**의존성**: AI 모델 클라이언트 (1-1단계)
**우선순위**: 낮음 (테스트용)

```bash
python ai_component_analyzer.py --project-name sampleSrc
```

**출력**: 콘솔에 분석 결과 출력

---

## 📋 권장 실행 시나리오

### 시나리오 1: 신규 프로젝트 전체 분석 (권장)
```bash
# 1단계: 기본 설정 확인
python ai_model_client.py

# 2단계: 기본 분석
python generate_hierarchy_report.py --project-name sampleSrc
python generate_erd_report.py --project-name sampleSrc

# 3단계: 통합 분석
python generate_ai_component_diagram.py --project-name sampleSrc
python generate_ai_report.py --project-name sampleSrc comprehensive local_gemma
```

**총 소요시간**: 약 3-4분
**생성 파일**: 4개 리포트

---

### 시나리오 2: 빠른 구조 파악
```bash
# 1단계: 기본 설정 확인
python ai_model_client.py

# 2단계: 핵심 분석만
python generate_hierarchy_report.py --project-name sampleSrc
python generate_erd_report.py --project-name sampleSrc
```

**총 소요시간**: 약 1분
**생성 파일**: 2개 리포트

---

### 시나리오 3: AI 중심 분석
```bash
# 1단계: AI 모델 확인
python ai_model_client.py

# 2단계: AI 분석
python generate_ai_component_diagram.py --project-name sampleSrc
python generate_ai_report.py --project-name sampleSrc --custom-prompt "보안 취약점에 집중해서 분석해주세요"
```

**총 소요시간**: 약 3분
**생성 파일**: 2개 리포트

---

### 시나리오 4: 특정 분석만 수행
```bash
# 보안 분석만
python generate_ai_report.py --project-name sampleSrc security local_gemma

# 코드 품질 분석만
python generate_ai_report.py --project-name sampleSrc code_quality local_gemma

# 아키텍처 분석만
python generate_ai_report.py --project-name sampleSrc architecture local_gemma
```

---

## ⚠️ 실행 전 필수 확인사항

### 1. 프로젝트 구조 확인
```
../project/sampleSrc/
├── src/                    # Java 소스 파일
├── DB_SCHEMA/             # 데이터베이스 스키마 CSV 파일
└── metadata.db            # 메타데이터베이스 (자동 생성)
```

### 2. AI 모델 상태 확인
```bash
# Ollama 서비스 실행 확인
curl http://localhost:11434/api/tags

# 모델 설치 확인
ollama list
```

### 3. 권한 확인
- `../project/sampleSrc/report/` 디렉토리 쓰기 권한
- `logs/` 디렉토리 쓰기 권한

---

## 🔧 문제 해결 가이드

### AI 모델 연결 실패 시
```bash
# 1. Ollama 서비스 상태 확인
python generate_ai_report.py --test-connection

# 2. 수동 연결 테스트
python ai_model_client.py

# 3. Ollama 재시작
ollama serve
```

### 메타데이터베이스 오류 시
```bash
# 1. 기존 DB 삭제 후 재생성
rm ../project/sampleSrc/metadata.db
python main.py --project-name sampleSrc --clean

# 2. 파서 상태 확인
python main.py --project-name sampleSrc --verbose
```

### 리포트 생성 실패 시
```bash
# 1. 출력 디렉토리 확인
ls -la ../project/sampleSrc/report/

# 2. 권한 확인
chmod 755 ../project/sampleSrc/report/

# 3. 상세 로그로 재실행
python generate_hierarchy_report.py --project-name sampleSrc --verbose
```

---

## 📊 성능 최적화 팁

### 1. 병렬 실행 (독립적인 분석들)
```bash
# 동시 실행 가능 (서로 독립적)
python generate_hierarchy_report.py --project-name sampleSrc &
python generate_erd_report.py --project-name sampleSrc &
wait
```

### 2. 캐시 활용
- 메타데이터베이스는 한 번 생성 후 재사용
- AI 분석 결과는 파일로 저장되어 재사용 가능

### 3. 리소스 관리
- AI 분석은 CPU/메모리 집약적이므로 동시 실행 제한
- Ollama 모델은 메모리에 로드되므로 충분한 RAM 확보

---

## 🎯 최종 권장사항

### 개발 단계별 실행 순서
1. **초기 개발**: 시나리오 2 (빠른 구조 파악)
2. **상세 분석**: 시나리오 1 (전체 분석)
3. **특정 이슈**: 시나리오 4 (특정 분석)
4. **최종 검토**: 시나리오 3 (AI 중심 분석)

### 운영 환경 배포 시
1. `config/ai_config.yaml`에서 `environment: production` 설정
2. vLLM 서비스 실행 확인
3. 배치 스크립트로 시나리오 1 자동 실행

---

*종속성을 고려한 순서대로 실행하면 안정적이고 효율적인 분석이 가능합니다.*
