# 1ë‹¨ê³„ ê°œë°œ í›„ ê°œì„ ì•ˆ

## 1. ê°œìš”

ë¦¬ë·° ë³´ê³ ì„œì—ì„œ ì§€ì ëœ ì£¼ìš” ë¬¸ì œì ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ê³„íšì„ ìˆ˜ë¦½í•˜ì˜€ìŠµë‹ˆë‹¤. í˜„ì¬ êµ¬í˜„ëœ ì‹œìŠ¤í…œì˜ ê¸°ë³¸ ê¸°ëŠ¥ì€ ì‘ë™í•˜ì§€ë§Œ, íŒŒì„œ ì •í™•ë„, ì„±ëŠ¥ ìµœì í™”, í™•ì¥ì„± ì¸¡ë©´ì—ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.

## 2. ìš°ì„ ìˆœìœ„ë³„ ê°œì„ ì•ˆ

### ğŸ”´ ìµœìš°ì„  ê°œì„ ì‚¬í•­ (ì¦‰ì‹œ ì ìš©)

#### 2.1 ì˜ˆì™¸ ì²˜ë¦¬ ë° ë¡œê¹… ê°œì„ 
**ë¬¸ì œì **: ë¹ˆ except ë¸”ë¡ê³¼ print ê¸°ë°˜ ë¡œê¹…ìœ¼ë¡œ ë””ë²„ê¹… ì–´ë ¤ì›€
**ê°œì„ ë°©ì•ˆ**:
```python
# í˜„ì¬ ì½”ë“œ ë¬¸ì œ
try:
    # íŒŒì‹± ë¡œì§
    pass
except:
    pass  # ì˜¤ë¥˜ ì •ë³´ ì†Œì‹¤

# ê°œì„ ëœ ì½”ë“œ
try:
    # íŒŒì‹± ë¡œì§
    pass
except ParseError as e:
    self.logger.error(f"íŒŒì‹± ì‹¤íŒ¨ {file_path}: {e}", exc_info=True)
    return None
except IOError as e:
    self.logger.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {file_path}: {e}")
    return None
```

**ì ìš© ê³„íš**:
1. `src/utils/logger.py` ìƒì„±í•˜ì—¬ í†µí•© ë¡œê¹… ì„¤ì •
2. ëª¨ë“  íŒŒì„œì™€ ì—”ì§„ì— êµ¬ì²´ì  ì˜ˆì™¸ ì²˜ë¦¬ ì ìš©
3. ë¡œê·¸ ë ˆë²¨ë³„ ìƒì„¸ ë©”ì‹œì§€ ë° ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ê¸°ë¡

#### 2.2 ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì™„ì„±
**ë¬¸ì œì **: PRD ìš”êµ¬ì‚¬í•­ì˜ í•µì‹¬ í…Œì´ë¸”ë“¤ ëˆ„ë½
**ê°œì„ ë°©ì•ˆ**:
```python
# ì¶”ê°€í•  í…Œì´ë¸”ë“¤
class Summary(Base):
    __tablename__ = 'summaries'
    # logic, vuln, perf, db_comment_suggestion ë“±

class EnrichmentLog(Base):
    __tablename__ = 'enrichment_logs'
    # LLM ë³´ê°• ì „í›„ ì‹ ë¢°ë„ ì¶”ì 

class VulnerabilityFix(Base):
    __tablename__ = 'vulnerability_fixes'
    # ë³´ì•ˆ ì·¨ì•½ì  ìˆ˜ì • ì œì•ˆ
```

**ì ìš© ê³„íš**:
1. ëˆ„ë½ëœ í…Œì´ë¸” ëª¨ë¸ ì¶”ê°€
2. ê¸°ì¡´ ì½”ë“œì—ì„œ ì´ í…Œì´ë¸”ë“¤ í™œìš©í•˜ëŠ” ë¡œì§ êµ¬í˜„
3. ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

#### 2.3 íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„
**ë¬¸ì œì **: thread_count ì„¤ì • ìˆì§€ë§Œ ì‹¤ì œ ìˆœì°¨ ì²˜ë¦¬
**ê°œì„ ë°©ì•ˆ**:
```python
# metadata_engine.py ê°œì„ 
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor

def analyze_files_parallel(self, file_paths: List[str], project_id: int):
    """íŒŒì¼ë“¤ì„ ë³‘ë ¬ë¡œ ë¶„ì„"""
    max_workers = self.config.get('processing', {}).get('max_workers', 4)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(self._analyze_single_file, file_path, project_id): file_path 
            for file_path in file_paths
        }
        
        results = []
        for future in concurrent.futures.as_completed(futures):
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                file_path = futures[future]
                self.logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {file_path}: {e}")
                
    return results
```

### ğŸŸ¡ ì¤‘ìš” ê°œì„ ì‚¬í•­ (ë‹¨ê¸° ì ìš©)

#### 2.4 íŒŒì„œ ì •í™•ë„ ê°œì„ 
**ë¬¸ì œì **: javalang ì œí•œì‚¬í•­ê³¼ ì •ê·œì‹ ê¸°ë°˜ JSP/MyBatis íŒŒì‹± ë¶€ì •í™•ì„±
**ê°œì„ ë°©ì•ˆ**:

**Phase 1: í˜„ì¬ íŒŒì„œ ê°œì„ **
```python
# java_parser.py ê°œì„ 
class ImprovedJavaParser(JavaParser):
    def __init__(self, config):
        super().__init__(config)
        self.fallback_parsers = []
        
        # JavaParser ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ (javalang ë³´ì™„)
        try:
            import javaparser
            self.fallback_parsers.append(javaparser)
        except ImportError:
            pass
            
    def parse_with_fallback(self, content: str, file_path: str):
        """ë‹¤ì¤‘ íŒŒì„œë¡œ í´ë°± ì§€ì›"""
        try:
            # ê¸°ë³¸ javalang ì‹œë„
            return self._parse_with_javalang(content)
        except Exception as e:
            self.logger.warning(f"javalang ì‹¤íŒ¨, í´ë°± ì‹œë„: {e}")
            
            # í´ë°± íŒŒì„œë“¤ ì‹œë„
            for parser in self.fallback_parsers:
                try:
                    return self._parse_with_fallback_parser(content, parser)
                except Exception:
                    continue
                    
            # ëª¨ë“  íŒŒì„œ ì‹¤íŒ¨ ì‹œ ë¶€ë¶„ ì •ë³´ë¼ë„ ì¶”ì¶œ
            return self._extract_basic_info_regex(content, file_path)
```

**Phase 2: Tree-sitter ë„ì… ì¤€ë¹„**
```python
# ìƒˆë¡œìš´ íŒŒì„œ ì¸í„°í˜ì´ìŠ¤
class ParserInterface(ABC):
    @abstractmethod
    def parse(self, content: str, file_path: str) -> ParseResult:
        pass
        
class TreeSitterJavaParser(ParserInterface):
    def __init__(self):
        # Tree-sitter Java grammar ì´ˆê¸°í™”
        pass
        
    def parse(self, content: str, file_path: str) -> ParseResult:
        # Tree-sitter ê¸°ë°˜ íŒŒì‹±
        pass
```

#### 2.5 MyBatis ë™ì  SQL ë¶„ì„ ê°•í™”
**ë¬¸ì œì **: ë™ì  íƒœê·¸ ì¤‘ì²© êµ¬ì¡° ë¶„ì„ ë¶€ì¡±
**ê°œì„ ë°©ì•ˆ**:
```python
class EnhancedMybatisParser:
    def analyze_dynamic_sql(self, element):
        """ë™ì  SQL ìµœëŒ€ í¬í•¨(superset) ë¶„ì„"""
        static_parts = []
        dynamic_parts = []
        
        # <if>, <choose>, <foreach> íƒœê·¸ë³„ ë¶„ì„
        for child in element:
            if child.tag in ['if', 'when']:
                # ì¡°ê±´ë¶€ ë¸”ë¡ - ìµœëŒ€ í¬í•¨ìœ¼ë¡œ ì²˜ë¦¬
                dynamic_parts.append(self._extract_all_possible_sql(child))
            elif child.tag == 'foreach':
                # ë°˜ë³µ ë¸”ë¡ - ë‹¨ì¼ í•­ëª©ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬
                dynamic_parts.append(self._convert_foreach_to_single(child))
            else:
                static_parts.append(child.text or '')
                
        return {
            'static_sql': ' '.join(static_parts),
            'dynamic_variations': dynamic_parts,
            'confidence': 0.7 if dynamic_parts else 0.9
        }
```

#### 2.6 ì‹ ë¢°ë„ ê³„ì‚° ì‹œìŠ¤í…œ êµ¬í˜„
**ë¬¸ì œì **: confidence í•„ë“œëŠ” ì •ì˜ë˜ì–´ ìˆì§€ë§Œ ì‹¤ì œ ê³„ì‚° ë¡œì§ ì—†ìŒ
**ê°œì„ ë°©ì•ˆ**:
```python
class ConfidenceCalculator:
    def __init__(self, config):
        self.weights = config.get('confidence', {}).get('weights', {
            'ast': 0.4,
            'static': 0.3, 
            'db_match': 0.2,
            'heuristic': 0.1
        })
        
    def calculate_parsing_confidence(self, parse_result: ParseResult) -> float:
        """íŒŒì‹± ê²°ê³¼ì˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.0
        
        # AST ì™„ì„±ë„
        if parse_result.ast_complete:
            confidence += self.weights['ast'] * 1.0
        elif parse_result.partial_ast:
            confidence += self.weights['ast'] * 0.6
            
        # ì •ì  ê·œì¹™ ë§¤ì¹­
        static_score = len(parse_result.matched_patterns) / parse_result.total_patterns
        confidence += self.weights['static'] * static_score
        
        # DB ìŠ¤í‚¤ë§ˆ ë§¤ì¹­ (í…Œì´ë¸”/ì»¬ëŸ¼ëª…)
        if parse_result.db_matches:
            db_score = len(parse_result.confirmed_tables) / len(parse_result.referenced_tables)
            confidence += self.weights['db_match'] * db_score
            
        # ë³µì¡ë„ íŒ¨ë„í‹°
        complexity_penalty = self._calculate_complexity_penalty(parse_result)
        
        return max(0.0, min(1.0, confidence - complexity_penalty))
```

### ğŸŸ¢ í–¥í›„ ê°œì„ ì‚¬í•­ (ì¤‘ì¥ê¸°)

#### 2.7 Tree-sitter ê¸°ë°˜ ë‹¤êµ­ì–´ íŒŒì„œ ë„ì…
**ëª©í‘œ**: better.md ì œì•ˆì‚¬í•­ ì ìš©
**êµ¬í˜„ ê³„íš**:
1. **Phase 1**: Tree-sitter Java grammar í†µí•©
2. **Phase 2**: JSP, JavaScript, TypeScript grammar ì¶”ê°€  
3. **Phase 3**: ì¦ë¶„ íŒŒì‹± ë° ì‹¤ì‹œê°„ ë¶„ì„ ì§€ì›

```python
# tree_sitter_parser.py
class TreeSitterParser:
    def __init__(self):
        self.languages = {
            'java': Language(tree_sitter_java.language(), 'java'),
            'javascript': Language(tree_sitter_javascript.language(), 'javascript'),
            # ì¶”ê°€ ì–¸ì–´ë“¤
        }
        
    def parse_with_incremental_update(self, old_tree, new_content, changes):
        """ì¦ë¶„ íŒŒì‹±ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ"""
        if old_tree:
            old_tree.edit(*changes)
            
        return self.parser.parse(new_content.encode(), old_tree)
```

#### 2.8 ANTLR ê¸°ë°˜ SQL/PL-SQL íŒŒì„œ
**ëª©í‘œ**: Oracle PL/SQL ë° ë³µì¡í•œ SQL êµ¬ë¬¸ ì •í™•í•œ ë¶„ì„
**êµ¬í˜„ ê³„íš**:
```python
# antlr_sql_parser.py
class ANTLRSQLParser:
    def __init__(self):
        # ANTLR PL/SQL grammar ë¡œë“œ
        self.lexer = PlsqlLexer()
        self.parser = PlsqlParser()
        
    def parse_plsql(self, sql_content: str):
        """PL/SQL í”„ë¡œì‹œì €/í‘ì…˜ ë¶„ì„"""
        input_stream = antlr4.InputStream(sql_content)
        lexer = self.lexer(input_stream)
        token_stream = antlr4.CommonTokenStream(lexer)
        parser = self.parser(token_stream)
        
        tree = parser.compilation_unit()
        
        # ë°©ë¬¸ì íŒ¨í„´ìœ¼ë¡œ AST ìˆœíšŒ
        visitor = PLSQLVisitor()
        return visitor.visit(tree)
```

#### 2.9 í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ (2ë‹¨ê³„ ì¤€ë¹„)
**ëª©í‘œ**: BGE-M3 + BM25 + ì¬ë­í‚¹ ì‹œìŠ¤í…œ
**êµ¬í˜„ ê³„íš**:
```python
# hybrid_retrieval.py  
class HybridRetriever:
    def __init__(self, config):
        # BGE-M3 ì„ë² ë”© ëª¨ë¸
        self.embedding_model = SentenceTransformer('BAAI/bge-m3')
        
        # BM25 ìŠ¤íŒŒìŠ¤ ê²€ìƒ‰
        self.bm25_index = None
        
        # ì¬ë­í‚¹ ëª¨ë¸
        self.reranker = CrossEncoder('BAAI/bge-reranker-base')
        
    def search(self, query: str, k: int = 20):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        # 1. ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰
        dense_results = self._dense_search(query, k)
        
        # 2. BM25 ìŠ¤íŒŒìŠ¤ ê²€ìƒ‰  
        sparse_results = self._sparse_search(query, k)
        
        # 3. ê²°ê³¼ ìœµí•©
        combined_results = self._combine_results(dense_results, sparse_results)
        
        # 4. êµì°¨ ì¸ì½”ë” ì¬ë­í‚¹
        reranked_results = self._rerank(query, combined_results)
        
        return reranked_results[:k]
```

#### 2.10 ë³´ì•ˆ ì·¨ì•½ì  ë¶„ì„ í†µí•©
**ëª©í‘œ**: SAST ë„êµ¬ ì—°ë™ìœ¼ë¡œ ë³´ì•ˆ ìš”ì•½ ìƒì„±
**êµ¬í˜„ ê³„íš**:
```python
# security_analyzer.py
class SecurityAnalyzer:
    def __init__(self, config):
        self.sast_tools = {
            'semgrep': SemgrepAnalyzer(),
            'codeql': CodeQLAnalyzer() if available else None
        }
        
    def analyze_vulnerabilities(self, project_path: str):
        """ë³´ì•ˆ ì·¨ì•½ì  ì¢…í•© ë¶„ì„"""
        results = {}
        
        for tool_name, analyzer in self.sast_tools.items():
            if analyzer:
                try:
                    tool_results = analyzer.scan(project_path)
                    results[tool_name] = self._process_results(tool_results)
                except Exception as e:
                    self.logger.error(f"{tool_name} ìŠ¤ìº” ì‹¤íŒ¨: {e}")
                    
        return self._consolidate_findings(results)
        
    def _process_results(self, raw_results):
        """SAST ê²°ê³¼ë¥¼ vulnerability_fixes í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        fixes = []
        for finding in raw_results:
            fix = VulnerabilityFix(
                vulnerability_type=finding.rule_id,
                severity=finding.severity,
                owasp_category=self._map_to_owasp(finding.rule_id),
                description=finding.message,
                fix_description=self._generate_fix_suggestion(finding),
                original_code=finding.code_snippet,
                fixed_code=self._suggest_fixed_code(finding),
                confidence=finding.confidence
            )
            fixes.append(fix)
        return fixes
```

## 3. êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: ê¸´ê¸‰ ê°œì„  (2ì£¼)
- [ ] í†µí•© ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ì˜ˆì™¸ ì²˜ë¦¬ ì „ë©´ ê°œì„   
- [ ] ëˆ„ë½ í…Œì´ë¸” ëª¨ë¸ ì¶”ê°€
- [ ] ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„
- [ ] ì‹ ë¢°ë„ ê³„ì‚° ê¸°ë³¸ ë¡œì§

### Phase 2: íŒŒì„œ ê°œì„  (4ì£¼)  
- [ ] Java íŒŒì„œ ë‹¤ì¤‘ í´ë°± ì‹œìŠ¤í…œ
- [ ] MyBatis ë™ì  SQL ê°•í™”
- [ ] CSV ë¡œë” ë©”ëª¨ë¦¬ ìµœì í™”
- [ ] ì˜ì¡´ì„± ë¶„ì„ AST ê¸°ë°˜ ê°œì„ 

### Phase 3: í™•ì¥ì„± ì¤€ë¹„ (6ì£¼)
- [ ] Tree-sitter Java íŒŒì„œ í†µí•©
- [ ] í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜ ì„¤ê³„
- [ ] ANTLR SQL íŒŒì„œ êµ¬í˜„
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° CI êµ¬ì¶•

### Phase 4: 2ë‹¨ê³„ ê¸°ë°˜ êµ¬ì¶• (8ì£¼)
- [ ] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ
- [ ] LLM í†µí•© ì¸í„°í˜ì´ìŠ¤  
- [ ] ë³´ì•ˆ ë¶„ì„ í†µí•©
- [ ] FastAPI ì›¹ ì„œë¹„ìŠ¤ ì¤€ë¹„

## 4. ì„±ëŠ¥ ê°œì„  ëª©í‘œ

### í˜„ì¬ ì„±ëŠ¥
- 100k LOC í”„ë¡œì íŠ¸: ìˆœì°¨ ì²˜ë¦¬ë¡œ ì˜ˆìƒ 60ë¶„+
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ëŒ€ìš©ëŸ‰ CSV ë¡œë”© ì‹œ ê³¼ë‹¤ ì‚¬ìš©
- íŒŒì‹± ì •í™•ë„: ë³µì¡í•œ êµ¬ë¬¸ì—ì„œ ë‚®ìŒ

### ëª©í‘œ ì„±ëŠ¥ (Phase 2 ì™„ë£Œ í›„)
- 100k LOC í”„ë¡œì íŠ¸: 30ë¶„ ë‚´ ì™„ë£Œ (PRD ìš”êµ¬ì‚¬í•­)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 50% ê°ì†Œ (ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬)
- íŒŒì‹± ì •í™•ë„: 95% ì´ìƒ (ë‹¤ì¤‘ íŒŒì„œ í´ë°±)

## 5. í’ˆì§ˆ ê´€ë¦¬ ê°•í™”

### í…ŒìŠ¤íŠ¸ ì „ëµ
```python
# tests/ êµ¬ì¡°
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_java_parser.py
â”‚   â”œâ”€â”€ test_mybatis_parser.py  
â”‚   â””â”€â”€ test_metadata_engine.py
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_end_to_end.py
â”‚   â””â”€â”€ test_project_analysis.py
â””â”€â”€ fixtures/
    â”œâ”€â”€ sample_java_files/
    â”œâ”€â”€ sample_mybatis_xml/
    â””â”€â”€ sample_databases/
```

### CI/CD íŒŒì´í”„ë¼ì¸
```yaml
# .github/workflows/ci.yml
name: Source Analyzer CI
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: pip install -r requirements.txt -r requirements-dev.txt
      - name: Run tests
        run: pytest tests/ --cov=src/
      - name: Run integration tests
        run: pytest tests/integration/ -v
```

## 6. ê²°ë¡ 

ì´ë²ˆ ê°œì„ ì•ˆì€ ë¦¬ë·°ì—ì„œ ì§€ì ëœ í•µì‹¬ ë¬¸ì œë“¤ì„ ë‹¨ê³„ì ìœ¼ë¡œ í•´ê²°í•˜ì—¬ ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ì†ŒìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. 

**ì¦‰ì‹œ ì ìš©í•  ìˆ˜ ìˆëŠ” ê°œì„ ì‚¬í•­**ë“¤ì„ ìš°ì„  ì²˜ë¦¬í•˜ì—¬ ì‹œìŠ¤í…œì˜ ì•ˆì •ì„±ì„ í™•ë³´í•˜ê³ , **ì¤‘ì¥ê¸°ì ìœ¼ë¡œëŠ” Tree-sitterì™€ ANTLR ë„ì…**ì„ í†µí•´ íŒŒì‹± ì •í™•ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¬ ê³„íšì…ë‹ˆë‹¤.

íŠ¹íˆ **PRDì—ì„œ ìš”êµ¬í•œ ì¬í˜„ìœ¨ ìš°ì„  ì •ì±…**ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ë‹¤ì¤‘ íŒŒì„œ í´ë°± ì‹œìŠ¤í…œê³¼ ì‹ ë¢°ë„ ì¶”ì ì„ ê°•í™”í•˜ì—¬, ë¶„ì„ ê²°ê³¼ì˜ ì‹ ë¢°ì„±ì„ ë³´ì¥í•˜ë©´ì„œë„ ëˆ„ë½ì„ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤.