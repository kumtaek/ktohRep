# 연관성 메타데이터 구축 상세 설계

## 1. 개요

본 문서는 `연관성구현방안.md`에 기술된 내용을 바탕으로, 소스코드 및 데이터베이스의 다양한 엔티티(파일, 클래스, 테이블 등) 간의 연관성을 계산하고, 이를 지속적으로 관리할 수 있는 메타데이터를 구축하는 방안을 상세히 설계한다.

## 2. 데이터 모델 확장: `Relatedness` 테이블 신설

엔티티 간의 연관성 점수를 효과적으로 저장하고 관리하기 위해, 기존 `Edge` 테이블을 수정하는 대신 새로운 `Relatedness` 테이블을 `phase1/models/database.py`에 추가한다. 이는 직접적인 호출/참조 관계(Edge)가 없는 엔티티 간의 연관성(예: 동일 디렉토리 위치)도 저장할 수 있게 하여 유연성을 높인다.

### `Relatedness` 테이블 스키마

```python
# phase1/models/database.py 에 추가될 클래스

from sqlalchemy import Column, Integer, String, Float, UniqueConstraint, ForeignKey
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class Relatedness(Base):
    __tablename__ = 'relatedness'

    id = Column(Integer, primary_key=True)
    project_id = Column(Integer, ForeignKey('project.project_id'), nullable=False)

    # 연관 관계의 두 주체
    source_type = Column(String(50), nullable=False)
    source_id = Column(Integer, nullable=False)
    target_type = Column(String(50), nullable=False)
    target_id = Column(Integer, nullable=False)

    # 연관성 점수 및 근거
    score = Column(Float, nullable=False, comment="연관성 점수 (0.0 ~ 1.0)")
    reason = Column(String(255), nullable=False, comment="연관성 판단 근거 (e.g., 'foreign_key', 'directory_proximity')")

    __table_args__ = (UniqueConstraint('project_id', 'source_type', 'source_id', 'target_type', 'target_id', 'reason', name='_source_target_reason_uc'),)

    def __repr__(self):
        return f"<Relatedness(score={self.score}, reason='{self.reason}')>"
```

## 3. 연관성 계산 파이프라인 설계

연관성 계산은 `phase1/scripts` 내에 `calculate_relatedness.py` 스크립트를 신설하여 수행한다. 이 스크립트는 프로젝트의 모든 엔티티를 조합하고, 여러 규칙에 따라 점수를 계산한 후 `Relatedness` 테이블에 저장/업데이트한다.

### 3.1. 메인 파이프라인 (`calculate_relatedness.py`)

```python
# phase1/scripts/calculate_relatedness.py (신규 생성)

import itertools
from ..models.database import DatabaseManager, File, Class, DbTable # 등
from ..models.relatedness import Relatedness # 새로 추가될 모델

class RelatednessCalculator:
    def __init__(self, project_id):
        self.project_id = project_id
        self.dbm = DatabaseManager(...) # 실제 DB 매니저 인스턴스화
        self.session = self.dbm.get_session()
        self.nodes = self._load_nodes() # 모든 엔티티 로드

    def run(self):
        # 모든 노드 쌍에 대해 연관성 계산
        for node1, node2 in itertools.combinations(self.nodes, 2):
            scores = {}

            # 1. 규칙 기반 점수 계산
            scores['directory'] = self.calculate_directory_score(node1, node2)
            scores['naming'] = self.calculate_naming_score(node1, node2)
            scores['db_fk'] = self.calculate_db_fk_score(node1, node2)
            # ... 기타 규칙 기반 스코어

            # 2. AI/LLM 기반 점수 계산 (향후 확장)
            # scores['semantic'] = self.calculate_semantic_score(node1, node2)

            # 3. 점수 통합 및 저장
            self.aggregate_and_store(node1, node2, scores)

    def _load_nodes(self):
        # DB에서 File, Class, DbTable 등 모든 분석 대상 엔티티를 로드하여
        # {'id': 1, 'type': 'file', 'path': '...', 'name': '...'} 형태의 딕셔너리 리스트로 반환
        # 예시: return self.dbm.get_all_entities(self.project_id)
        pass

    def aggregate_and_store(self, node1, node2, scores):
        # 각 점수와 가중치를 기반으로 최종 점수를 계산하고 DB에 저장
        # 예: final_score = max(scores.values()) # 가장 강한 연관성을 점수로 채택
        # 또는 weighted_score = w1*s1 + w2*s2 + ...
        for reason, score in scores.items():
            if score > 0.1: # 임계값 이상일 경우에만 저장
                # DB에 (node1, node2, score, reason) 저장하는 로직
                self.update_relatedness_in_db(node1, node2, score, reason)

    # ... 각 calculate 함수들 ...

    def calculate_directory_score(self, node1, node2):
        # ... (구현 상세는 아래 참조)
        pass

    def calculate_naming_score(self, node1, node2):
        # ... (구현 상세는 아래 참조)
        pass

    def calculate_db_fk_score(self, node1, node2):
        # ... (구현 상세은 아래 참조)
        pass

    def update_relatedness_in_db(self, node1, node2, score, reason):
        # ... (구현 상세은 아래 참조)
        pass
```

### 3.2. 규칙 기반 점수 계산 로직 (Code Snippets)

#### 1. 디렉토리 근접성 점수

```python
# RelatednessCalculator 클래스 내 메소드
import os

def calculate_directory_score(self, node1, node2):
    path1 = node1.get('path')
    path2 = node2.get('path')

    if not path1 or not path2:
        return 0.0

    # 경로가 동일한 경우, 깊이 차이를 기반으로 점수 계산
    if path1 == path2:
        return 0.8 # 동일 디렉토리면 높은 점수

    # 공통 경로 찾기
    common_path = os.path.commonpath([path1, path2])

    # 경로 깊이 계산 (루트 디렉토리 제외)
    depth1 = path1.count(os.sep) - common_path.count(os.sep)
    depth2 = path2.count(os.sep) - common_path.count(os.sep)

    # 공통 경로로부터의 상대적 깊이 차이
    # 깊이가 얕을수록 (즉, 공통 경로에 가까울수록) 높은 점수 부여
    depth_diff_score = 1.0 / (1 + abs(depth1 - depth2))

    # 최종 점수는 공통 경로의 깊이와 상대적 깊이 차이를 조합
    # 예: 공통 경로가 깊을수록, 그리고 두 경로의 깊이 차이가 적을수록 높은 점수
    # 여기서는 단순화를 위해 공통 경로의 깊이 자체를 활용
    common_depth = common_path.count(os.sep)
    score = common_depth / max(path1.count(os.sep), path2.count(os.sep)) if max(path1.count(os.sep), path2.count(os.sep)) > 0 else 0

    return score * 0.6 # 가중치 0.6 적용
```

#### 2. 이름 유사도 점수

```python
# RelatednessCalculator 클래스 내 메소드
from difflib import SequenceMatcher

def calculate_naming_score(self, node1, node2):
    name1 = node1.get('name', '').lower()
    name2 = node2.get('name', '').lower()

    if not name1 or not name2:
        return 0.0

    # "User" vs "UserService", "UserController" 등 접두사/접미사 관계 파악
    if name1.startswith(name2) or name2.startswith(name1):
        return 0.7

    # SequenceMatcher를 이용한 일반적인 문자열 유사도
    similarity = SequenceMatcher(None, name1, name2).ratio()
    return similarity * 0.5 # 가중치 0.5 적용
```

#### 3. DB Foreign Key 점수

```python
# RelatednessCalculator 클래스 내 메소드
def calculate_db_fk_score(self, node1, node2):
    # self.joins 에 미리 DB의 모든 FK 관계를 로드했다고 가정
    # 예: self.joins = self.dbm.get_all_foreign_keys()
    if not (node1.get('type') == 'table' and node2.get('type') == 'table'):
        return 0.0

    # 두 테이블 간에 FK 관계가 있는지 확인
    for join in self.joins:
        if (join['table1'] == node1['name'] and join['table2'] == node2['name']) or \
           (join['table1'] == node2['name'] and join['table2'] == node1['name']):
            return 0.95 # FK는 매우 강한 연관성
    return 0.0
```

### 3.3. AI/LLM 기반 점수 계산 설계

AI 기반 점수는 계산 비용이 높으므로, 규칙 기반으로 강한 연관성을 찾지 못한 노드 쌍에 대해 선택적으로 수행한다.

```python
# RelatednessCalculator 클래스 내 메소드
# from ..llm import LLMManager # phase1의 LLM 모듈 활용

def calculate_semantic_score(self, node1, node2):
    # 1. LLM에 전달할 코드 컨텍스트 추출
    code1 = self.get_code_snippet(node1) # 노드에 해당하는 코드 조각 가져오기
    code2 = self.get_code_snippet(node2)

    if not code1 or not code2:
        return 0.0

    # 2. 프롬프트 구성
    prompt = f"""
두 코드 스니펫은 비즈니스 로직상 얼마나 연관되어 있습니까? 0.0에서 1.0 사이의 점수로만 대답하세요.

Snippet 1 ({node1.get('name', 'N/A')}):
{code1}

Snippet 2 ({node2.get('name', 'N/A')}):
{code2}

연관성 점수:"""

    # 3. LLM 호출 및 결과 파싱
    # llm = LLMManager()
    # response = llm.ask(prompt)
    # try:
    #     score = float(response.strip())
    #     return score
    # except ValueError:
    #     return 0.0 # LLM 응답이 숫자가 아닐 경우 0 반환
    return 0.0 # 실제 구현 시 주석 해제

def get_code_snippet(self, node):
    # 노드 타입에 따라 해당 코드 조각을 DB에서 조회하거나 파일에서 읽어오는 로직
    # 예: File 노드면 파일 내용 읽기, Class 노드면 클래스 정의 부분 읽기
    pass
```

## 4. 데이터베이스 저장 로직

계산된 점수는 `Relatedness` 테이블에 저장/업데이트한다. `UniqueConstraint`를 활용하여 중복 저장을 방지하고, 점수가 바뀔 경우 업데이트한다.

```python
# RelatednessCalculator 클래스 내 메소드
def update_relatedness_in_db(self, node1, node2, score, reason):
    # 정렬하여 source/target 순서 일관성 유지
    # 노드 딕셔너리에 'id'와 'type' 키가 있다고 가정
    s_node, t_node = sorted([node1, node2], key=lambda x: (x.get('type', ''), x.get('id', 0)))

    existing = self.session.query(Relatedness).filter_by(
        project_id=self.project_id,
        source_type=s_node.get('type'),
        source_id=s_node.get('id'),
        target_type=t_node.get('type'),
        target_id=t_node.get('id'),
        reason=reason
    ).first()

    if existing:
        # 기존 점수보다 높을 경우에만 업데이트
        if score > existing.score:
            existing.score = score
            self.session.commit() # 변경사항 커밋
    else:
        # 새 Relatedness 객체 생성
        new_relatedness = Relatedness(
            project_id=self.project_id,
            source_type=s_node.get('type'),
            source_id=s_node.get('id'),
            target_type=t_node.get('type'),
            target_id=t_node.get('id'),
            score=score,
            reason=reason
        )
        self.session.add(new_relatedness)
        self.session.commit() # 새 객체 커밋
```

## 5. 실행 계획

1. **1단계: DB 스키마 변경**
   - `phase1/models/database.py`에 `Relatedness` 클래스 추가.
   - DB 마이그레이션 수행.
2. **2단계: 규칙 기반 계산기 구현**
   - `phase1/scripts/calculate_relatedness.py` 스크립트 및 `RelatednessCalculator` 클래스 골격 생성.
   - 규칙 기반 점수 계산 메소드(디렉토리, 이름, FK 등) 상세 구현.
   - 계산된 점수를 `Relatedness` 테이블에 저장하는 로직 구현.
3. **3단계: AI/LLM 연동 (선택적 고도화)**
   - 규칙 기반으로 연관성을 찾지 못한 노드 쌍에 대해 `calculate_semantic_score` 로직 구현.
   - `phase1`의 LLM 인프라와 연동하여 실제 API 호출 및 결과 처리 구현.
