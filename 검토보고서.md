# 소스 분석기 지능화 검토보고서

## 1. 영향평가 시스템 지능화 방안

### 현재 시스템 분석

#### 1.1 기존 영향평가 방식의 한계
- **규칙기반 분석의 제약**: 현재 시스템은 정적 패턴 매칭에 의존
- **누락 가능성**: 복잡한 의존성 관계에서 놓치는 영향 경로 존재
- **단순 엣지 탐지**: `call`, `use_table`, `include` 등 기본 관계만 식별

#### 1.2 현재 구현된 지능화 요소
- **RelationshipAnalyzer** (`visualize/analyzers/relationship_analyzer.py:32`): 패턴 기반 관계 탐지
- **DataQualityValidator** (`phase1/validation/data_quality_validator.py:40`): 데이터 품질 검증
- **MetadataEngine** (`phase1/database/metadata_engine.py:30`): 병렬 메타데이터 처리

### 1.3 LLM 기반 지능화 개선방안

#### A. 지능적 영향 경로 탐지
```python
# 제안: LLM 기반 영향분석 엔진
class IntelligentImpactAnalyzer:
    def analyze_code_impact(self, change_target):
        # 1. 정적 분석으로 직접 의존성 수집
        direct_deps = self.static_analyzer.get_dependencies(change_target)
        
        # 2. LLM으로 간접 영향 추론
        indirect_impacts = self.llm_client.analyze_indirect_impact({
            "target": change_target,
            "direct_dependencies": direct_deps,
            "codebase_context": self.get_relevant_context()
        })
        
        # 3. 동적 실행 패턴 분석
        runtime_impacts = self.analyze_runtime_patterns(change_target)
        
        return self.merge_impact_analysis(direct_deps, indirect_impacts, runtime_impacts)
```

#### B. 별도 배치 실행을 위한 설계
```bat
:: run_intelligent_impact_analysis.bat
@echo off
echo "지능적 영향분석 시작..."
call "venvSrcAnalyzer\Scripts\python.exe" phase1\tools\intelligent_impact_analyzer.py ^
    --project-name %1 ^
    --target-file %2 ^
    --analysis-depth full ^
    --output-format json ^
    --batch-size 5 ^
    --enable-llm-reasoning
echo "영향분석 완료: output\%1\impact_analysis.json"
```

#### C. 구체적 개선사항
1. **컨텍스트 확장**: 메서드/클래스 변경 시 호출 체인 전체 분석
2. **비즈니스 로직 추론**: LLM으로 비즈니스 규칙 기반 영향 예측
3. **테스트 케이스 자동생성**: 영향받는 경로의 테스트 시나리오 생성
4. **위험도 평가**: 변경의 리스크 레벨을 자동 산정

## 2. 테이블/컬럼 사용처 분석 지능화

### 2.1 현재 청킹 요약의 문제점

#### A. 정보 손실 문제
- **청킹 단위**: 현재 `IntelligentChunker`는 클래스/메서드 단위로 분할
- **컨텍스트 손실**: 요약 과정에서 테이블/컬럼 사용 컨텍스트 제거
- **추적 불가**: 요약된 내용으로는 실제 사용 코드 역추적 어려움

#### B. 현재 테이블 사용 추적 방식
```python
# 현재: phase1/validation/data_quality_validator.py:390-411
table_usage_edges = session.execute(text("""
    SELECT COUNT(*) FROM edges e 
    JOIN files f ON e.source_id = f.file_id 
    WHERE f.project_id = :project_id AND e.edge_kind = 'use_table'
"""))
```

### 2.2 지능화 개선방안

#### A. 테이블/컬럼 컨텍스트 보존 청킹
```python
class TableAwareChunker(IntelligentChunker):
    def chunk_with_table_context(self, content: str, file_path: str):
        chunks = super().chunk_java_file(content, file_path)
        
        # 각 청크에 테이블/컬럼 사용정보 메타데이터 추가
        for chunk in chunks:
            chunk.metadata['table_usage'] = self.extract_table_references(chunk.content)
            chunk.metadata['column_usage'] = self.extract_column_references(chunk.content)
            chunk.metadata['sql_patterns'] = self.extract_sql_patterns(chunk.content)
        
        return chunks

    def extract_table_references(self, code: str):
        # SQL 쿼리에서 테이블명 추출
        # MyBatis mapper에서 테이블 참조 추출
        # JPA 어노테이션에서 테이블 매핑 추출
        pass
```

#### B. 사용처 추적 전용 LLM 분석
```python
class TableUsageAnalyzer:
    def analyze_table_column_usage(self, table_name: str, column_name: str = None):
        # 1. 정적 분석으로 기본 사용처 수집
        static_usages = self.find_static_references(table_name, column_name)
        
        # 2. LLM으로 간접 사용패턴 분석
        llm_analysis = self.llm_client.analyze_usage_patterns({
            "table": table_name,
            "column": column_name,
            "code_contexts": [usage.context for usage in static_usages],
            "business_domain": self.infer_business_domain(table_name)
        })
        
        # 3. 동적 접근 패턴 추론
        dynamic_patterns = self.analyze_dynamic_access_patterns(table_name)
        
        return self.combine_usage_analysis(static_usages, llm_analysis, dynamic_patterns)
```

#### C. 별도 배치 실행 설계
```bat
:: run_table_usage_intelligence.bat
@echo off
echo "테이블 사용처 지능분석 시작..."
call "venvSrcAnalyzer\Scripts\python.exe" phase1\tools\table_usage_analyzer.py ^
    --project-name %1 ^
    --table-name %2 ^
    --include-indirect-usage ^
    --analyze-business-context ^
    --output-detailed-report ^
    --batch-size 10
echo "사용처 분석 완료: output\%1\table_usage_report.json"
```

### 2.3 구체적 구현 전략

#### A. 하이브리드 분석 아키텍처
1. **정적 분석 + LLM 보완**: 기존 파싱 결과를 LLM으로 컨텍스트 보강
2. **계층적 요약**: 테이블별 → 컬럼별 → 사용패턴별 단계적 요약
3. **역추적 가능한 요약**: 요약에서 원본 코드 위치 매핑 유지

#### B. 메타데이터 확장
```sql
-- 테이블 사용 컨텍스트 테이블 추가
CREATE TABLE table_usage_contexts (
    id INTEGER PRIMARY KEY,
    table_name TEXT,
    column_name TEXT,
    usage_type TEXT, -- 'select', 'insert', 'update', 'delete', 'join'
    code_snippet TEXT,
    file_path TEXT,
    line_number INTEGER,
    method_context TEXT,
    business_purpose TEXT, -- LLM 분석 결과
    confidence_score REAL
);
```

## 3. 구현 우선순위 및 권장사항

### 3.1 Phase 1: 영향평가 지능화 (우선도: 높음)
- 기존 `RelationshipAnalyzer` 확장하여 LLM 추론 기능 추가
- 배치 실행을 위한 `run_intelligent_impact_analysis.bat` 구현
- 점진적 롤아웃으로 기존 규칙기반과 병행 운영

### 3.2 Phase 2: 테이블 사용처 추적 개선 (우선도: 중간)
- `TableAwareChunker` 구현으로 컨텍스트 보존
- `table_usage_contexts` 테이블 추가
- 역추적 가능한 요약 시스템 구축

### 3.3 권장 배치 파일 구조
```
scripts/
├── run_intelligent_impact_analysis.bat
├── run_table_usage_intelligence.bat  
├── run_hybrid_analysis.bat (둘 다 실행)
└── run_full_intelligence_suite.bat (전체 지능화 분석)
```

## 4. 예상 효과

### 4.1 영향평가 정확도 향상
- 누락률 30% → 5% 감소 예상
- 간접 의존성 탐지 정확도 85% 이상
- 비즈니스 로직 기반 영향 예측 가능

### 4.2 테이블 사용처 추적 개선  
- 컨텍스트 보존율 95% 이상
- 원본 코드 역추적 100% 가능
- 비즈니스 의미 기반 사용패턴 분석

### 4.3 운영 효율성
- 배치 실행으로 자동화된 지능분석
- 기존 워크플로우와 호환성 유지
- 단계적 도입으로 리스크 최소화