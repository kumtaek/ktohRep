# Source Analyzer Configuration
# Phase 1: Metadata Generation Configuration

# Database Configuration
database:
  type: sqlite  # sqlite for dev, oracle for prod
  sqlite:
    path: "./data/metadata.db"
    wal_mode: true
  oracle:
    host: "localhost"
    port: 1521
    service_name: "orcl"
    username: "analyzer"
    password: "password"

# Vector Store Configuration  
vector_store:
  type: faiss
  faiss:
    index_path: "./data/faiss.index"
    model_name: "BAAI/bge-m3"  # Multi-language embedding model
    dimension: 1024
    
# Parser Configuration
parsers:
  java:
    enabled: true
    parser_type: "javaparser"  # javaparser or tree-sitter
    java_version: 8
    
  jsp:
    enabled: true
    parser_type: "antlr"
    
  mybatis:
    enabled: true
    parser_type: "jsqlparser"
    
  sql:
    enabled: true
    parser_type: "jsqlparser"
    oracle_dialect: true
    
  tree_sitter:
    enabled: false  # for future use
    languages: ["java", "javascript", "typescript", "python"]

# LLM Configuration (for enrichment)
llm:
  enabled: true
  base_model: "qwen2.5-7b"
  fallback_model: "qwen2.5-32b"
  # 환경변수로 주입 권장: set VLLM_ENDPOINT=http://<HOST>:<PORT>
  vllm_endpoint: "${VLLM_ENDPOINT}"
  temperature: 0.0
  max_tokens: 2048
  
# Embedding Models
embedding:
  models:
    - name: "BAAI/bge-m3"
      type: "multilingual"
      max_length: 8192
      batch_size: 32
    - name: "jhgan00/ko-sentence-transformers" 
      type: "korean"
      max_length: 512
      batch_size: 16

# Processing Configuration
processing:
  max_workers: 4
  chunk_size: 512
  chunk_overlap: 50
  confidence_threshold: 0.5
  
# Output Configuration
output:
  metadata_only: true  # No source code storage
  include_line_ranges: true
  include_confidence: true
  log_enrichment: true

# File Patterns
file_patterns:
  include:
    - "**/*.java"
    - "**/*.jsp" 
    - "**/*.xml"
    - "**/*.properties"
  exclude:
    - "**/target/**"
    - "**/build/**"
    - "**/test/**"
    - "**/.git/**"

# DB Schema Files
db_schema:
  required_files:
    - "ALL_TABLES.csv"
    - "ALL_TAB_COLUMNS.csv" 
    - "PK_INFO.csv"
  path_template: "./PROJECT/{project_name}/DB_SCHEMA/"

# Logging
logging:
  level: "DEBUG"
  file: "./logs/analyzer.log"
  max_size: "100MB"
  backup_count: 3

# Web Server (Backend) Configuration
server:
  host: "127.0.0.1"
  port: 8000
  debug: true
  api_prefix: "/api"
  # Backend CORS settings
  cors:
    enabled: true
    allow_origins: ["*"]
    allow_methods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
    allow_headers: ["*"]
    credentials: false
    expose_headers: []
  # Backend logging overrides (fallbacks to top-level logging if omitted)
  log_file: "./logs/backend.log"
  log_level: "DEBUG"
  # Static file serving
  static:
    enabled: false
    folder: "./web-dashboard/frontend/dist"
    url_path: "/static"

# LLM Assist (Phase1) — Optional overrides for providers
llm_assist:
  enabled: true
  provider: auto           # auto|ollama|vllm|openai
  low_conf_threshold: 0.6
  max_calls_per_run: 50
  file_max_lines: 1200
  temperature: 0.0
  max_tokens: 512
  strict_json: true
  cache: true
  cache_dir: ./out/llm_cache
  log_prompt: false
  dry_run: false
  fallback_to_ollama: true
  enrich:
    table_comments:
      enabled: true
      max_tables: 25
    column_comments:
      enabled: true
      max_columns: 50
    sql_summary:
      enabled: true
      max_items: 30
    method_summary:
      enabled: true
      max_items: 30
    jsp_summary:
      enabled: true
      max_items: 30
  # Provider details (override env when set)
  vllm_base_url: ${VLLM_ENDPOINT}
  vllm_api_key: ${VLLM_API_KEY}
  vllm_model: Qwen2.5
  ollama_host: http://localhost:11434
  ollama_model: gemma3:1b
