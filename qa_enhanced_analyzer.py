"""
ê³ ê¸‰ Q&A ìë™ ë¶„ì„ ì‹œìŠ¤í…œ
ì‹¤ì œ ì½”ë“œë² ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•œ ë‹µë³€ ìƒì„±
"""

import os
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import logging
import traceback

class EnhancedCodeAnalyzer:
    """ì‹¤ì œ ì½”ë“œë² ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ê³ ê¸‰ ë¶„ì„ê¸°"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.logger = logging.getLogger(__name__)
        
    def analyze_join_object_issue(self, q_content: str) -> Dict[str, Any]:
        """Join ê°ì²´ ê´€ë ¨ ì´ìŠˆ ì „ë¬¸ ë¶„ì„"""
        analysis = {
            'issue_type': 'join_object_error',
            'root_cause': '',
            'affected_files': [],
            'solution': '',
            'confidence': 0.0
        }
        
        try:
            # JSP MyBatis íŒŒì„œ íŒŒì¼ ë¶„ì„
            parser_file = self.project_root / 'phase1' / 'parsers' / 'jsp_mybatis_parser.py'
            if parser_file.exists():
                analysis['affected_files'].append(str(parser_file))
                
                with open(parser_file, 'r', encoding='utf-8') as f:
                    parser_content = f.read()
                
                # ë¬¸ì œ ë¼ì¸ ì°¾ê¸°
                if '_extract_sql_patterns_regex' in parser_content:
                    # ë°˜í™˜ê°’ êµ¬ì¡° ë¶„ì„
                    method_pattern = r'def\s+_extract_sql_patterns_regex.*?return\s+([^}]+)'
                    method_match = re.search(method_pattern, parser_content, re.DOTALL)
                    
                    if method_match:
                        return_statement = method_match.group(1)
                        if 'joins, filters' in return_statement:
                            analysis['root_cause'] = 'ë©”ì†Œë“œê°€ íŠœí”Œ (joins, filters)ë¥¼ ë°˜í™˜í•˜ì§€ë§Œ í˜¸ì¶œë¶€ì—ì„œ ë‹¨ì¼ ê°’ìœ¼ë¡œ ë°›ìŒ'
                            analysis['confidence'] = 0.95
                        
                # í˜¸ì¶œë¶€ ë¶„ì„
                call_patterns = [
                    r'sql_joins\s*=\s*self\._extract_sql_patterns_regex\(',
                    r'([a-zA-Z_][a-zA-Z0-9_]*)\s*=\s*self\._extract_sql_patterns_regex\('
                ]
                
                for pattern in call_patterns:
                    matches = re.findall(pattern, parser_content)
                    if matches:
                        analysis['solution'] = f"í˜¸ì¶œë¶€ì—ì„œ íŠœí”Œ ì–¸íŒ¨í‚¹ í•„ìš”: {matches[0]}, _ = self._extract_sql_patterns_regex(...)"
                        
            # Database ëª¨ë¸ ë¶„ì„
            db_model_file = self.project_root / 'phase1' / 'models' / 'database.py'
            if db_model_file.exists():
                analysis['affected_files'].append(str(db_model_file))
                
                with open(db_model_file, 'r', encoding='utf-8') as f:
                    db_content = f.read()
                
                # Join í´ë˜ìŠ¤ ì •ì˜ í™•ì¸
                if 'class Join' in db_content:
                    join_attrs = re.findall(r'(l_table|l_col|r_table|r_col)\s*=', db_content)
                    if join_attrs:
                        analysis['confidence'] = min(analysis['confidence'] + 0.05, 1.0)
                        
        except Exception as e:
            self.logger.error(f"Join ê°ì²´ ì´ìŠˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return analysis
    
    def analyze_method_signature_mismatch(self, file_path: str, method_name: str) -> Dict[str, Any]:
        """ë©”ì†Œë“œ ì‹œê·¸ë‹ˆì²˜ ë¶ˆì¼ì¹˜ ë¶„ì„"""
        analysis = {
            'method_found': False,
            'return_type': '',
            'parameters': [],
            'call_sites': [],
            'mismatch_details': []
        }
        
        try:
            target_file = Path(file_path)
            if target_file.exists():
                with open(target_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ë©”ì†Œë“œ ì •ì˜ ì°¾ê¸°
                method_pattern = rf'def\s+{re.escape(method_name)}\s*\([^)]*\)\s*->\s*([^:]+):'
                method_match = re.search(method_pattern, content)
                
                if method_match:
                    analysis['method_found'] = True
                    analysis['return_type'] = method_match.group(1).strip()
                
                # ë©”ì†Œë“œ í˜¸ì¶œ ì‚¬ì´íŠ¸ ì°¾ê¸°
                call_pattern = rf'{re.escape(method_name)}\s*\('
                call_matches = re.finditer(call_pattern, content)
                
                for match in call_matches:
                    line_num = content[:match.start()].count('\n') + 1
                    line_content = content.split('\n')[line_num - 1].strip()
                    analysis['call_sites'].append({
                        'line': line_num,
                        'content': line_content
                    })
                    
        except Exception as e:
            self.logger.error(f"ë©”ì†Œë“œ ì‹œê·¸ë‹ˆì²˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return analysis
    
    def find_similar_patterns_in_codebase(self, error_pattern: str) -> List[Dict[str, Any]]:
        """ì½”ë“œë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬í•œ íŒ¨í„´ ê²€ìƒ‰"""
        similar_issues = []
        
        try:
            # Python íŒŒì¼ë“¤ì—ì„œ ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰
            python_files = list(self.project_root.rglob('*.py'))
            
            for py_file in python_files:
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # ìœ ì‚¬í•œ ë©”ì†Œë“œ í˜¸ì¶œ íŒ¨í„´ ì°¾ê¸°
                    if 'extract_sql_patterns' in error_pattern:
                        pattern = r'([a-zA-Z_][a-zA-Z0-9_]*)\s*=\s*self\._extract_sql_patterns_\w+\('
                        matches = re.finditer(pattern, content)
                        
                        for match in matches:
                            line_num = content[:match.start()].count('\n') + 1
                            line_content = content.split('\n')[line_num - 1].strip()
                            
                            similar_issues.append({
                                'file': str(py_file),
                                'line': line_num,
                                'pattern': match.group(0),
                                'content': line_content,
                                'potential_issue': 'íŠœí”Œ ì–¸íŒ¨í‚¹ ëˆ„ë½ ê°€ëŠ¥ì„±'
                            })
                            
                except Exception:
                    continue
                    
        except Exception as e:
            self.logger.error(f"ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return similar_issues
    
    def generate_solution_code(self, issue_analysis: Dict[str, Any]) -> str:
        """êµ¬ì²´ì ì¸ í•´ê²° ì½”ë“œ ìƒì„±"""
        if issue_analysis['issue_type'] == 'join_object_error':
            return """
## ğŸ› ï¸ êµ¬ì²´ì  ìˆ˜ì • ì½”ë“œ

### ìˆ˜ì • ëŒ€ìƒ íŒŒì¼: `phase1/parsers/jsp_mybatis_parser.py`

**ë¬¸ì œ ë¼ì¸ (765):**
```python
# í˜„ì¬ (ë¬¸ì œ)
sql_joins = self._extract_sql_patterns_regex(sql_content, sql_unit)
joins.extend(sql_joins)
```

**ìˆ˜ì •ëœ ì½”ë“œ (í•´ê²°):**
```python
# ìˆ˜ì • (í•´ê²°)
sql_joins, _ = self._extract_sql_patterns_regex(sql_content, sql_unit)
joins.extend(sql_joins)
```

### ì›ë¦¬ ì„¤ëª…:
- `_extract_sql_patterns_regex` ë©”ì†Œë“œëŠ” `Tuple[List[Join], List[RequiredFilter]]` ë°˜í™˜
- ê¸°ì¡´ ì½”ë“œëŠ” íŠœí”Œì„ ë‹¨ì¼ ë³€ìˆ˜ì— í• ë‹¹ â†’ `sql_joins`ê°€ íŠœí”Œì´ ë¨
- `joins.extend(sql_joins)` ì‹œ íŠœí”Œì˜ ê° ìš”ì†Œ(ë¦¬ìŠ¤íŠ¸)ë¥¼ ê°œë³„ ì•„ì´í…œìœ¼ë¡œ ì¶”ê°€
- ê²°ê³¼ì ìœ¼ë¡œ `joins` ë¦¬ìŠ¤íŠ¸ì— ë¦¬ìŠ¤íŠ¸ ê°ì²´ë“¤ì´ ë“¤ì–´ê°€ì„œ ì†ì„± ì ‘ê·¼ ì˜¤ë¥˜ ë°œìƒ
"""
        return "í•´ê²° ë°©ì•ˆì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤."

class SmartQAProcessor:
    """ìŠ¤ë§ˆíŠ¸ Q&A ì²˜ë¦¬ê¸°"""
    
    def __init__(self, project_root: str = "."):
        self.analyzer = EnhancedCodeAnalyzer(project_root)
        self.logger = logging.getLogger(__name__)
        
    def process_question_intelligently(self, q_content: str, timestamp: str) -> str:
        """ì§€ëŠ¥í˜• ì§ˆë¬¸ ì²˜ë¦¬"""
        
        # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
        question_type = self._classify_question(q_content)
        
        if question_type == 'join_object_issue':
            return self._handle_join_object_question(q_content, timestamp)
        elif question_type == 'parsing_error':
            return self._handle_parsing_error_question(q_content, timestamp)
        elif question_type == 'database_issue':
            return self._handle_database_question(q_content, timestamp)
        else:
            return self._handle_general_question(q_content, timestamp)
    
    def _classify_question(self, q_content: str) -> str:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜"""
        content_lower = q_content.lower()
        
        if 'join' in content_lower and ('object' in content_lower or 'l_table' in content_lower):
            return 'join_object_issue'
        elif 'parsing' in content_lower or 'parser' in content_lower:
            return 'parsing_error'
        elif 'database' in content_lower or 'sql' in content_lower:
            return 'database_issue'
        else:
            return 'general'
    
    def _handle_join_object_question(self, q_content: str, timestamp: str) -> str:
        """Join ê°ì²´ ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬"""
        
        # ì „ë¬¸ ë¶„ì„ ìˆ˜í–‰
        analysis = self.analyzer.analyze_join_object_issue(q_content)
        solution_code = self.analyzer.generate_solution_code(analysis)
        similar_patterns = self.analyzer.find_similar_patterns_in_codebase('extract_sql_patterns')
        
        answer = f"""# Join ê°ì²´ ë°˜í™˜ êµ¬ì¡° ë¬¸ì œ ì „ë¬¸ ë¶„ì„

## ğŸ“… ë¶„ì„ ì •ë³´
- **ë¶„ì„ ì‹œê°„**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}
- **ì§ˆë¬¸ íŒŒì¼**: Q_{timestamp}.md
- **ë¬¸ì œ ìœ í˜•**: Join ê°ì²´ ì†ì„± ì ‘ê·¼ ì˜¤ë¥˜
- **ë¶„ì„ ì‹ ë¢°ë„**: {analysis['confidence']:.1%}

## ğŸ¯ ê·¼ë³¸ ì›ì¸ ë¶„ì„

### í•µì‹¬ ë¬¸ì œ
{analysis['root_cause']}

### ì˜í–¥ë°›ëŠ” íŒŒì¼ë“¤
"""
        for file_path in analysis['affected_files']:
            answer += f"- `{file_path}`\n"
        
        answer += solution_code
        
        # ìœ ì‚¬ íŒ¨í„´ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
        if similar_patterns:
            answer += "\n## ğŸ” ì½”ë“œë² ì´ìŠ¤ ë‚´ ìœ ì‚¬ íŒ¨í„´ ê²€í† \n\n"
            for pattern in similar_patterns[:3]:  # ìµœëŒ€ 3ê°œ
                answer += f"**{Path(pattern['file']).name}:{pattern['line']}**\n"
                answer += f"```python\n{pattern['content']}\n```\n"
                answer += f"âš ï¸ {pattern['potential_issue']}\n\n"
        
        answer += f"""
## âœ… ê²€ì¦ ë°©ë²•
1. ìˆ˜ì • í›„ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸:
   ```bash
   python phase1/main.py
   ```
2. ë¡œê·¸ì—ì„œ "Join ê°ì²´ ìƒì„± ì„±ê³µ" ë©”ì‹œì§€ í™•ì¸
3. `'list' object has no attribute` ì˜¤ë¥˜ ì‚¬ë¼ì§ í™•ì¸

## ğŸ“Š ì˜í–¥ ë¶„ì„
- **ì¦‰ì‹œ í•´ê²°**: âœ… ë‹¨ìˆœ ì½”ë“œ ìˆ˜ì •ìœ¼ë¡œ í•´ê²°
- **ë¶€ì‘ìš©**: âŒ ì—†ìŒ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
- **í…ŒìŠ¤íŠ¸ í•„ìš”**: âš ï¸ íŒŒì‹± ê²°ê³¼ ê²€ì¦ ê¶Œì¥

---
*SourceAnalyzer ê³ ê¸‰ ë¶„ì„ ì‹œìŠ¤í…œ - ì‹¤ì œ ì½”ë“œ ê¸°ë°˜ ë¶„ì„*
"""
        
        return answer
    
    def _handle_parsing_error_question(self, q_content: str, timestamp: str) -> str:
        """íŒŒì‹± ì—ëŸ¬ ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬"""
        return f"""# íŒŒì‹± ì˜¤ë¥˜ ë¶„ì„ ë‹µë³€

## ğŸ“… ë¶„ì„ ì •ë³´  
- **ë¶„ì„ ì‹œê°„**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}
- **ì§ˆë¬¸ íŒŒì¼**: Q_{timestamp}.md

## ğŸ” íŒŒì‹± ì˜¤ë¥˜ ì¼ë°˜ í•´ê²° ê°€ì´ë“œ

### ê³µí†µ ì›ì¸ë“¤
- ë©”ì†Œë“œ ì‹œê·¸ë‹ˆì²˜ ë¶ˆì¼ì¹˜
- ë°˜í™˜ê°’ íƒ€ì… ì˜¤ë¥˜
- ì˜ˆì™¸ ì²˜ë¦¬ ëˆ„ë½

### ì§„ë‹¨ ì ˆì°¨
1. ë¡œê·¸ íŒŒì¼ ìƒì„¸ ê²€í† 
2. ë©”ì†Œë“œ ì •ì˜ì™€ í˜¸ì¶œë¶€ ë¹„êµ
3. íƒ€ì… íŒíŠ¸ì™€ ì‹¤ì œ ë°˜í™˜ê°’ ê²€ì¦

---
*ìë™ ìƒì„±ëœ íŒŒì‹± ì˜¤ë¥˜ ë¶„ì„*
"""
    
    def _handle_database_question(self, q_content: str, timestamp: str) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬"""
        return f"""# ë°ì´í„°ë² ì´ìŠ¤ ì´ìŠˆ ë¶„ì„

## ğŸ“… ë¶„ì„ ì •ë³´
- **ë¶„ì„ ì‹œê°„**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}  
- **ì§ˆë¬¸ íŒŒì¼**: Q_{timestamp}.md

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ê¶Œì¥ì‚¬í•­

### ì²´í¬ì‚¬í•­ë“¤
- SQLAlchemy ëª¨ë¸ ì •ì˜ í™•ì¸
- ì™¸ë˜í‚¤ ê´€ê³„ ì„¤ì • ê²€í† 
- ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì¼ì¹˜ì„± í™•ì¸

---
*ìë™ ìƒì„±ëœ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„*
"""
    
    def _handle_general_question(self, q_content: str, timestamp: str) -> str:
        """ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬"""
        return f"""# ê°œë°œ ì§ˆë¬¸ ìë™ ë¶„ì„

## ğŸ“… ë¶„ì„ ì •ë³´
- **ë¶„ì„ ì‹œê°„**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}
- **ì§ˆë¬¸ íŒŒì¼**: Q_{timestamp}.md

## ğŸ“‹ ì¼ë°˜ ê°œë°œ ê¶Œì¥ì‚¬í•­

### ë¬¸ì œ í•´ê²° ì ˆì°¨
1. ë¡œê·¸ íŒŒì¼ í™•ì¸
2. ê´€ë ¨ ì½”ë“œ ê²€í† 
3. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
4. ì ì§„ì  ìˆ˜ì • ì ìš©

---
*ìë™ ìƒì„±ëœ ì¼ë°˜ ë¶„ì„*
"""

# ê¸°ì¡´ QAMonitor í´ë˜ìŠ¤ ì—…ë°ì´íŠ¸
class QAMonitor:
    """Q&A íŒŒì¼ ëª¨ë‹ˆí„°ë§ ë° ìë™ ë‹µë³€ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, dev_report_dir: str = "./Dev.Report", check_interval: int = 300):
        self.dev_report_dir = Path(dev_report_dir)
        self.check_interval = check_interval
        self.processed_files = set()
        self.smart_processor = SmartQAProcessor()
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('qa_monitor.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Dev.Report ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„±
        self.dev_report_dir.mkdir(exist_ok=True)
        
        self.logger.info(f"QA ëª¨ë‹ˆí„° ì´ˆê¸°í™”: {self.dev_report_dir}, ê°„ê²©: {self.check_interval}ì´ˆ")
    
    def find_q_files_without_answers(self) -> List[Path]:
        """ë‹µë³€ì´ ì—†ëŠ” Q íŒŒì¼ë“¤ ì°¾ê¸°"""
        q_files = list(self.dev_report_dir.glob("Q_*.md"))
        unanswered_files = []
        
        for q_file in q_files:
            match = re.match(r'Q_(\d{8}_\d{4})\.md', q_file.name)
            if match:
                timestamp = match.group(1)
                corresponding_a_file = self.dev_report_dir / f"A_{timestamp}.md"
                
                if not corresponding_a_file.exists() and str(q_file) not in self.processed_files:
                    unanswered_files.append(q_file)
                    self.logger.info(f"ë‹µë³€ ëŒ€ê¸° Q íŒŒì¼: {q_file.name}")
        
        return unanswered_files
    
    def generate_answer_for_q_file(self, q_file_path: Path) -> bool:
        """Q íŒŒì¼ì— ëŒ€í•œ ì§€ëŠ¥í˜• ë‹µë³€ ìƒì„±"""
        try:
            self.logger.info(f"Q íŒŒì¼ ë‹µë³€ ìƒì„± ì‹œì‘: {q_file_path.name}")
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
            match = re.match(r'Q_(\d{8}_\d{4})\.md', q_file_path.name)
            if not match:
                self.logger.error(f"ì˜ëª»ëœ Q íŒŒì¼ í˜•ì‹: {q_file_path.name}")
                return False
            
            timestamp = match.group(1)
            
            # Q íŒŒì¼ ë‚´ìš© ì½ê¸°
            with open(q_file_path, 'r', encoding='utf-8') as f:
                q_content = f.read()
            
            # ì§€ëŠ¥í˜• ë‹µë³€ ìƒì„±
            answer_content = self.smart_processor.process_question_intelligently(q_content, timestamp)
            
            # A íŒŒì¼ ìƒì„±
            a_file_path = self.dev_report_dir / f"A_{timestamp}.md"
            with open(a_file_path, 'w', encoding='utf-8') as f:
                f.write(answer_content)
            
            # ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
            self.processed_files.add(str(q_file_path))
            
            self.logger.info(f"ë‹µë³€ ìƒì„± ì™„ë£Œ: {a_file_path.name}")
            return True
            
        except Exception as e:
            self.logger.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return False
    
    def monitor_and_process(self):
        """ë©”ì¸ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        self.logger.info("=== Q&A ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ===")
        self.logger.info(f"ì²´í¬ ê°„ê²©: {self.check_interval}ì´ˆ")
        
        while True:
            try:
                unanswered_files = self.find_q_files_without_answers()
                
                if unanswered_files:
                    self.logger.info(f"ğŸ“ {len(unanswered_files)}ê°œ ë¯¸ë‹µë³€ Q íŒŒì¼ ë°œê²¬")
                    
                    for q_file in unanswered_files:
                        success = self.generate_answer_for_q_file(q_file)
                        if success:
                            self.logger.info(f"âœ… ë‹µë³€ ì™„ë£Œ: {q_file.name}")
                        else:
                            self.logger.error(f"âŒ ë‹µë³€ ì‹¤íŒ¨: {q_file.name}")
                        
                        # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
                        import time
                        time.sleep(3)
                else:
                    self.logger.info("ğŸ“­ ìƒˆë¡œìš´ Q íŒŒì¼ ì—†ìŒ")
                
                self.logger.info(f"â° {self.check_interval}ì´ˆ í›„ ì¬ì²´í¬...")
                import time
                time.sleep(self.check_interval)
                
            except KeyboardInterrupt:
                self.logger.info("ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­")
                break
            except Exception as e:
                self.logger.error(f"âŒ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                import time
                time.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ ëŒ€ê¸°

if __name__ == "__main__":
    # ì‹¤í–‰
    import argparse
    
    parser = argparse.ArgumentParser(description='ê³ ê¸‰ Q&A ìë™ ëª¨ë‹ˆí„°ë§')
    parser.add_argument('--interval', type=int, default=300, help='ì²´í¬ ê°„ê²©(ì´ˆ)')
    parser.add_argument('--dev-report-dir', type=str, default='./Dev.Report', help='Dev.Report ê²½ë¡œ')
    
    args = parser.parse_args()
    
    monitor = QAMonitor(dev_report_dir=args.dev_report_dir, check_interval=args.interval)
    monitor.monitor_and_process()