"""
Q íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ A íŒŒì¼ ìƒì„±í•˜ëŠ” ê³ ê¸‰ ë¶„ì„ê¸°
"""

import os
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import logging

class ProjectCodeAnalyzer:
    """í”„ë¡œì íŠ¸ ì½”ë“œ ìë™ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.logger = logging.getLogger(__name__)
        
        # ë¶„ì„ ëŒ€ìƒ íŒŒì¼ íŒ¨í„´ë“¤
        self.analysis_patterns = {
            'parsers': 'phase1/parsers/*.py',
            'models': 'phase1/models/*.py',
            'database': 'phase1/database/*.py',
            'utils': 'phase1/utils/*.py',
            'main': 'phase1/main.py',
            'config': 'config/**/*.yaml',
            'logs': 'logs/*.log'
        }
    
    def analyze_question_context(self, q_content: str) -> Dict[str, Any]:
        """Q íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ íŒŒì•…"""
        context = {
            'question_type': 'general',
            'mentioned_files': [],
            'mentioned_methods': [],
            'mentioned_errors': [],
            'keywords': [],
            'priority': 'medium'
        }
        
        try:
            # ì–¸ê¸‰ëœ íŒŒì¼ë“¤ ì¶”ì¶œ
            file_patterns = [
                r'`([^`]+\.py)`',
                r'`([^`]+\.java)`',
                r'([a-zA-Z_][a-zA-Z0-9_]*\.py)',
                r'([a-zA-Z_][a-zA-Z0-9_]*_parser\.py)'
            ]
            
            for pattern in file_patterns:
                matches = re.findall(pattern, q_content)
                context['mentioned_files'].extend(matches)
            
            # ì–¸ê¸‰ëœ ë©”ì†Œë“œë“¤ ì¶”ì¶œ
            method_patterns = [
                r'`([a-zA-Z_][a-zA-Z0-9_]*)\(`',
                r'([a-zA-Z_][a-zA-Z0-9_]*)\s*ë©”ì†Œë“œ',
                r'([a-zA-Z_][a-zA-Z0-9_]*)\s*í•¨ìˆ˜'
            ]
            
            for pattern in method_patterns:
                matches = re.findall(pattern, q_content)
                context['mentioned_methods'].extend(matches)
            
            # ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ
            error_patterns = [
                r"'([^']*object has no attribute[^']*)'",
                r'`([^`]*Error[^`]*)`',
                r'ì˜¤ë¥˜[:\s]*([^\n]+)',
                r'ì—ëŸ¬[:\s]*([^\n]+)'
            ]
            
            for pattern in error_patterns:
                matches = re.findall(pattern, q_content)
                context['mentioned_errors'].extend(matches)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = ['Join', 'SQL', 'íŒŒì‹±', 'ê°ì²´', 'ë°˜í™˜', 'êµ¬ì¡°', 'íŠœí”Œ', 'ë¦¬ìŠ¤íŠ¸']
            context['keywords'] = [kw for kw in keywords if kw.lower() in q_content.lower()]
            
            # ìš°ì„ ìˆœìœ„ ê²°ì •
            if any('critical' in err.lower() or 'error' in err.lower() for err in context['mentioned_errors']):
                context['priority'] = 'high'
            elif context['mentioned_methods'] or context['mentioned_files']:
                context['priority'] = 'medium'
            
        except Exception as e:
            self.logger.warning(f"ì§ˆë¬¸ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return context
    
    def analyze_mentioned_files(self, mentioned_files: List[str]) -> Dict[str, Any]:
        """ì–¸ê¸‰ëœ íŒŒì¼ë“¤ ì‹¤ì œ ë¶„ì„"""
        file_analysis = {}
        
        for file_name in mentioned_files:
            try:
                # íŒŒì¼ ê²½ë¡œ í•´ê²°
                file_paths = list(self.project_root.rglob(file_name))
                if not file_paths:
                    # íŒŒì¼ëª…ë§Œìœ¼ë¡œ ê²€ìƒ‰
                    file_paths = list(self.project_root.rglob(f"*{file_name}*"))
                
                for file_path in file_paths[:1]:  # ì²« ë²ˆì§¸ ë§¤ì¹˜ë§Œ ë¶„ì„
                    analysis = self._analyze_single_file(file_path)
                    file_analysis[str(file_path)] = analysis
                    
            except Exception as e:
                self.logger.warning(f"íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ {file_name}: {e}")
        
        return file_analysis
    
    def _analyze_single_file(self, file_path: Path) -> Dict[str, Any]:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        analysis = {
            'exists': False,
            'size': 0,
            'last_modified': '',
            'methods': [],
            'classes': [],
            'imports': [],
            'key_patterns': []
        }
        
        try:
            if not file_path.exists():
                return analysis
            
            analysis['exists'] = True
            analysis['size'] = file_path.stat().st_size
            analysis['last_modified'] = datetime.fromtimestamp(
                file_path.stat().st_mtime
            ).strftime('%Y-%m-%d %H:%M:%S')
            
            # íŒŒì¼ ë‚´ìš© ë¶„ì„ (Python íŒŒì¼ë§Œ)
            if file_path.suffix == '.py':
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ë©”ì†Œë“œ ì¶”ì¶œ
                method_matches = re.findall(r'def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(', content)
                analysis['methods'] = list(set(method_matches))
                
                # í´ë˜ìŠ¤ ì¶”ì¶œ
                class_matches = re.findall(r'class\s+([a-zA-Z_][a-zA-Z0-9_]*)', content)
                analysis['classes'] = list(set(class_matches))
                
                # ì„í¬íŠ¸ ì¶”ì¶œ
                import_matches = re.findall(r'(?:from|import)\s+([a-zA-Z_][a-zA-Z0-9_.]*)', content)
                analysis['imports'] = list(set(import_matches))
                
                # í•µì‹¬ íŒ¨í„´ ê²€ìƒ‰
                key_patterns = ['Join', 'SqlUnit', 'return', 'Tuple', 'List']
                analysis['key_patterns'] = [
                    pattern for pattern in key_patterns 
                    if pattern in content
                ]
        
        except Exception as e:
            self.logger.warning(f"íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ {file_path}: {e}")
        
        return analysis
    
    def find_related_issues(self, context: Dict[str, Any]) -> List[Dict[str, str]]:
        """ê´€ë ¨ ì´ìŠˆë“¤ ê²€ìƒ‰"""
        issues = []
        
        # ë¡œê·¸ íŒŒì¼ì—ì„œ ê´€ë ¨ ì˜¤ë¥˜ ê²€ìƒ‰
        try:
            log_files = list(self.project_root.rglob('*.log'))
            for log_file in log_files:
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        log_content = f.read()
                    
                    # ì–¸ê¸‰ëœ ì—ëŸ¬ì™€ ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ ì—”íŠ¸ë¦¬ ì°¾ê¸°
                    for error in context.get('mentioned_errors', []):
                        if error.lower() in log_content.lower():
                            issues.append({
                                'type': 'log_match',
                                'file': str(log_file),
                                'error': error,
                                'context': 'ë¡œê·¸ì—ì„œ ë™ì¼ ì—ëŸ¬ íŒ¨í„´ ë°œê²¬'
                            })
                            
                except Exception as e:
                    self.logger.debug(f"ë¡œê·¸ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ {log_file}: {e}")
                    
        except Exception as e:
            self.logger.warning(f"ê´€ë ¨ ì´ìŠˆ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return issues
    
    def generate_detailed_answer(self, q_content: str, timestamp: str) -> str:
        """ìƒì„¸í•œ ë‹µë³€ ìƒì„±"""
        
        # 1. ì§ˆë¬¸ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        context = self.analyze_question_context(q_content)
        
        # 2. ì–¸ê¸‰ëœ íŒŒì¼ë“¤ ë¶„ì„
        file_analysis = self.analyze_mentioned_files(context['mentioned_files'])
        
        # 3. ê´€ë ¨ ì´ìŠˆ ê²€ìƒ‰
        related_issues = self.find_related_issues(context)
        
        # 4. ì¢…í•© ë‹µë³€ ìƒì„±
        answer = self._build_comprehensive_answer(q_content, context, file_analysis, related_issues, timestamp)
        
        return answer
    
    def _build_comprehensive_answer(self, q_content: str, context: Dict[str, Any], 
                                  file_analysis: Dict[str, Any], related_issues: List[Dict[str, str]], 
                                  timestamp: str) -> str:
        """ì¢…í•© ë‹µë³€ ì‘ì„±"""
        
        answer_parts = []
        
        # í—¤ë”
        answer_parts.append(f"""# ê°œë°œ ì§ˆë¬¸ ìë™ ë¶„ì„ ë‹µë³€

## ğŸ“… ë¶„ì„ ì •ë³´
- **ë¶„ì„ ì‹œê°„**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}
- **ì§ˆë¬¸ íŒŒì¼**: Q_{timestamp}.md
- **ìš°ì„ ìˆœìœ„**: {context['priority'].upper()}

## ğŸ” ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼

### ì–¸ê¸‰ëœ êµ¬ì„±ìš”ì†Œ
""")
        
        # ì–¸ê¸‰ëœ íŒŒì¼ë“¤
        if context['mentioned_files']:
            answer_parts.append("**íŒŒì¼ë“¤:**")
            for file_name in set(context['mentioned_files']):
                answer_parts.append(f"- `{file_name}`")
            answer_parts.append("")
        
        # ì–¸ê¸‰ëœ ë©”ì†Œë“œë“¤
        if context['mentioned_methods']:
            answer_parts.append("**ë©”ì†Œë“œë“¤:**")
            for method in set(context['mentioned_methods']):
                answer_parts.append(f"- `{method}()`")
            answer_parts.append("")
        
        # ë°œê²¬ëœ ì—ëŸ¬ë“¤
        if context['mentioned_errors']:
            answer_parts.append("**ì—ëŸ¬ ë©”ì‹œì§€ë“¤:**")
            for error in set(context['mentioned_errors']):
                answer_parts.append(f"- `{error}`")
            answer_parts.append("")
        
        # íŒŒì¼ ë¶„ì„ ê²°ê³¼
        if file_analysis:
            answer_parts.append("## ğŸ“‹ íŒŒì¼ ë¶„ì„ ê²°ê³¼")
            for file_path, analysis in file_analysis.items():
                if analysis['exists']:
                    answer_parts.append(f"""
### `{Path(file_path).name}`
- **í¬ê¸°**: {analysis['size']:,} ë°”ì´íŠ¸
- **ìˆ˜ì •ì¼**: {analysis['last_modified']}
- **ë©”ì†Œë“œ ìˆ˜**: {len(analysis['methods'])}ê°œ
- **í´ë˜ìŠ¤ ìˆ˜**: {len(analysis['classes'])}ê°œ
""")
                    
                    if analysis['methods']:
                        key_methods = [m for m in analysis['methods'] if any(kw in m.lower() for kw in ['extract', 'parse', 'join'])]
                        if key_methods:
                            answer_parts.append("**í•µì‹¬ ë©”ì†Œë“œë“¤:**")
                            for method in key_methods[:5]:
                                answer_parts.append(f"- `{method}()`")
                            answer_parts.append("")
        
        # ê´€ë ¨ ì´ìŠˆë“¤
        if related_issues:
            answer_parts.append("## ğŸš¨ ë°œê²¬ëœ ê´€ë ¨ ì´ìŠˆ")
            for issue in related_issues[:3]:  # ìµœëŒ€ 3ê°œë§Œ
                answer_parts.append(f"- **{issue['type']}**: {issue['context']}")
            answer_parts.append("")
        
        # ê¶Œì¥ì‚¬í•­
        answer_parts.append("""## ğŸ’¡ ë¶„ì„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­

### ğŸ¯ ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­
- ì–¸ê¸‰ëœ ë©”ì†Œë“œì˜ ë°˜í™˜ê°’ íƒ€ì… ê²€ì¦
- ê´€ë ¨ íŒŒì¼ë“¤ì˜ ìµœê·¼ ë³€ê²½ì‚¬í•­ ê²€í† 
- ë¡œê·¸ íŒŒì¼ì—ì„œ ìƒì„¸ ì˜¤ë¥˜ ì»¨í…ìŠ¤íŠ¸ í™•ì¸

### ğŸ”§ êµ¬ì²´ì  í•´ê²° ì ‘ê·¼ë²•
1. **ê°ì²´ íƒ€ì… ê²€ì¦**: `isinstance()` ë˜ëŠ” `type()` ì‚¬ìš©í•œ ë””ë²„ê¹…
2. **ë°˜í™˜ê°’ êµ¬ì¡° í™•ì¸**: ë©”ì†Œë“œ ì‹œê·¸ë‹ˆì²˜ì™€ ì‹¤ì œ ë°˜í™˜ê°’ ë¹„êµ
3. **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**: ë¬¸ì œê°€ ë˜ëŠ” ë©”ì†Œë“œì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±

### âš ï¸ ì£¼ì˜ì‚¬í•­
- ì½”ë“œ ìˆ˜ì • ì „ í˜„ì¬ ìƒíƒœ ë°±ì—…
- ë³€ê²½ í›„ ì „ì²´ í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
- ë¡œê·¸ ë ˆë²¨ì„ DEBUGë¡œ ì„¤ì •í•˜ì—¬ ìƒì„¸ ì¶”ì 

## ğŸ“Š ë¶„ì„ ìš”ì•½
- **ë¶„ì„ëœ í‚¤ì›Œë“œ**: {len(context['keywords'])}ê°œ
- **ê²€í†  ëŒ€ìƒ íŒŒì¼**: {len(file_analysis)}ê°œ
- **ë°œê²¬ëœ ê´€ë ¨ ì´ìŠˆ**: {len(related_issues)}ê°œ

---
*SourceAnalyzer ìë™ ë¶„ì„ ì‹œìŠ¤í…œì— ì˜í•´ ìƒì„±ë¨*
""")
        
        return "\n".join(answer_parts)

class AutoAnswerGenerator:
    """ìë™ ë‹µë³€ ìƒì„± í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.analyzer = ProjectCodeAnalyzer(project_root)
        self.logger = logging.getLogger(__name__)
    
    def process_q_file(self, q_file_path: Path) -> Optional[str]:
        """Q íŒŒì¼ ì²˜ë¦¬í•˜ì—¬ A íŒŒì¼ ìƒì„±"""
        try:
            # Q íŒŒì¼ ì½ê¸°
            with open(q_file_path, 'r', encoding='utf-8') as f:
                q_content = f.read()
            
            self.logger.info(f"Q íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {q_file_path.name}")
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
            match = re.match(r'Q_(\d{8}_\d{4})\.md', q_file_path.name)
            if not match:
                self.logger.error(f"ì˜ëª»ëœ Q íŒŒì¼ í˜•ì‹: {q_file_path.name}")
                return None
            
            timestamp = match.group(1)
            
            # ìƒì„¸ ë¶„ì„ ë° ë‹µë³€ ìƒì„±
            answer_content = self.analyzer.generate_detailed_answer(q_content, timestamp)
            
            # A íŒŒì¼ ê²½ë¡œ ê²°ì •
            a_file_path = q_file_path.parent / f"A_{timestamp}.md"
            
            # A íŒŒì¼ ìƒì„±
            with open(a_file_path, 'w', encoding='utf-8') as f:
                f.write(answer_content)
            
            self.logger.info(f"A íŒŒì¼ ìƒì„± ì™„ë£Œ: {a_file_path.name}")
            return str(a_file_path)
            
        except Exception as e:
            self.logger.error(f"Q íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

def create_answer_for_question(q_file_path: str) -> bool:
    """ì™¸ë¶€ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ ë‹µë³€ ìƒì„± í•¨ìˆ˜"""
    try:
        generator = AutoAnswerGenerator()
        result = generator.process_q_file(Path(q_file_path))
        return result is not None
    except Exception as e:
        print(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return False

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰
    import sys
    
    if len(sys.argv) > 1:
        q_file_path = sys.argv[1]
        success = create_answer_for_question(q_file_path)
        if success:
            print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ: {q_file_path}")
        else:
            print(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {q_file_path}")
    else:
        print("ì‚¬ìš©ë²•: python qa_auto_analyzer.py Q_YYYYMMDD_HMS.md")